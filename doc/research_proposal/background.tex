\section{Background}
The atmospheric boundary layer (ABL) is a highly turbulent flow consisting of a wide spectrum of turbulent eddies (whirling motions). Explicitly solving the Navier-Stokes equations for all scales of these eddies is called direct numerical simulation (DNS). For DNS, the computational mesh has to be fine enough to represent even the smallest eddies, making it very computationally demanding \citep{moengNUMERICALMODELSLargeEddy2015}. Instead of resolving all scales, one could choose to only resolve the largest, most energetic scales explicitly and model the smaller scales. This approach is known as large-eddy simulation (LES). The Dutch Atmospheric Large-Eddy Simulation (DALES) model, developed by \citet{heusFormulationDutchAtmospheric2010}, is an LES model that is used for fundamental research of atmospheric processes.

Although LES is computationally less expensive than DNS for a given domain size, it remains resource-intensive. The majority of the computing time arises from loops that perform some calculation on all grid points, such as calculating derivatives. Typically, these calculations are independent of one another, meaning that they can be carried out in parallel. Graphics Processing Units (GPUs) are particularly well suited for parallel computing; unlike Central Processing Units (CPUs), which consist of up to tens of processing cores, a modern GPU can have thousands of processing cores performing calculations in parallel \citep{elsterNvidiaHopperGPU2022}, offering massive potential speed up for applications.

Moving calculations from CPUs to GPUs is a nontrivial task. Programmers need to adapt their software to effectively utilize a GPU. GPUs can be programmed using standard programming languages like C/C++, Fortran, Python, and others. To this end, specialized programming models are available that allow the programmer to manage a GPU. Examples of such programming models are: Compute Unified Device Architecture (CUDA) from NVIDIA, Open Computing Language (OpenCL), and Heterogeneous-Compute Interface for Portability from AMD. These models require rewriting the original CPU code into code that can run on GPUs, so-called \emph{kernels} \citep{owensGPUComputing2008}. 
Alternatively, one can choose to offload calculations using a programming model based on \emph{compiler directives}. Compiler directives are instructions to the compiler to perform some action on a piece of code. These directives look like comments. Instead of rewriting code, the programmer places compiler directives over parallelizable loops to offload them to a GPU. The compiler will then generate the kernels by itself. An example of a directive-based programming model is Open Accelerators (OpenACC). Working with OpenACC offers multiple benefits over traditional, lower-level programming models like CUDA \citep{herdmanAcceleratingHydrocodesOpenACC2012}:

\begin{itemize}
    \item Productivity: OpenACC requires minimal addition of lines of code to an existing codebase. This makes it possible for a programmer to accelerate large sections of a program in a relatively short amount of time. 
    \item Single source code: since OpenACC directives are essentially comments within the source code, only one version of the source code needs to be maintained. This approach is less error-prone compared to maintaining separate CPU and GPU versions, as required by CUDA and OpenCL. When a CPU version of the code is desired, the code can be recompiled for CPUs, and the OpenACC directives will be disregarded.
    \item Performance: CUDA and OpenCL applications require more manual optimizations of algorithms than OpenACC. For this reason, it is not uncommon that an OpenACC implementation can outperform a CUDA or OpenCL application, especially when little time has been spent on optimizing the application. However, since CUDA and OpenCL allow more fine-grained control over the GPU hardware, algorithms can be optimized much further than possible with OpenACC.
\end{itemize}

