@article{Schalkwijk2012,
   abstract = {Exploiting the GPU by jerôme Schalkwijk, eric j. Griffith, fritS h. PoSt, and harm j. j. jonker Processor clock speeds have increased exponentially over the last several decades. This has gone a long way toward supplying the necessary computational power for running these numerical simulations. Yet the computational demands of the atmospheric models have outpaced even this exponential growth. Most numerical simulation codes have been paral-lelized so that they can take advantage of the extra computational power provided by supercomputers or computational clusters. After years of predictable evolution, though, the high-performance computing landscape is now changing. Computer central processing units (CPUs) are now increasing in number of cores rather than clock speed. Specialized processing units such as graphics processing units (GPUs, or, more commonly, video cards) and field-programmable gate arrays (FPGAs) are being used increasingly for general-purpose numerical computing. Computational clusters and supercomputing facilities now have computing nodes with traditional processors, specialized processors , or both. The number of processing cores in computing nodes is also increasing. These changes mean that adapting numerical codes will be increasingly important if they are to get the most out of the available computing facilities. However, these changes also offer new opportunities. By taking advantage of specialized processing units, some simulations may no longer need a cluster at all, which would allow them to return to the realm of the desktop computer. The GPU, in particular, is becoming a mature platform for running numerical simulations. It was designed to perform the intensive matrix projection calculations associated with gaming graphics. In order to efficiently and quickly perform such calculations, modern GPUs are designed as massively parallel calculating devices. Aided by the vast commercial market for visually high-performing computer games, these GPUs have experienced tre-C OMPUTATIONAL ATMOSPHERIC SCIENCE. Advances in atmospheric science have been strongly coupled with technological advances in computational resources. This started early in the twentieth century when it became apparent that an analytical solution to the Navier-Stokes equations in the context of atmospheric weather prediction would not be feasible. Richardson pioneered the numerical approach to weather prediction in 1922 using pencil and paper, but the first successful forecasts were not made until the 1950s, when digital computers became available. Since that time, the field of numerical weather and climate modeling has continued to grow, and its predictive accuracy has increased, as it has continued to take advantage of increasing computer power. Today, atmospheric science relies heavily on numerical modeling on a variety of scales. Climate and weather predictions cover entire continents in large-scale models, whereas mesoscale models provide more detailed simulations of selected regions. On smaller scales, turbulent boundary layer processes and clouds are studied in high-resolution models like large-eddy simulations. Regardless of the scale, all of these models are computationally intensive. Brought to you by TU DELFT | Unauthenticated | Downloaded 05/22/23 01:05 PM UTC},
   author = {Jerôme Schalkwijk and Eric J. Griffith and Frits H. Post and Harm J.J. Jonker},
   doi = {10.1175/BAMS-D-11-00059.1},
   issn = {00030007},
   issue = {3},
   journal = {Bulletin of the American Meteorological Society},
   month = {3},
   pages = {307-314},
   publisher = {American Meteorological Society},
   title = {High-Performance Simulations of Turbulent Clouds on a Desktop PC: Exploiting the GPU},
   volume = {93},
   url = {https://journals.ametsoc.org/view/journals/bams/93/3/bams-d-11-00059_1.xml},
   year = {2012},
}
@article{Elster2022,
   abstract = {At GTC 2022, Nvidia announced a new product family that aims to cover from small enterprise workloads through exascale high performance computing (HPC) and trillion-parameter AI models. This column highlights the most interesting features of their new Hopper graphical processing unit (GPU) and Grace central processing unit (CPU) computer chips and the Hopper product family. We also discuss some of the history behind Nvidia technologies and their most useful features for computational scientists, such as the Hopper DPX dynamic programming (DP) instruction set, increased number of SMs, and FP 8 tensor core availability. Also included are descriptions of the new Hopper Clustered SMs architecture and updated NVSwitch technologies that integrate their new ARM-based Grace CPU.},
   author = {Anne C Elster and Tor A Haugdahl},
   doi = {10.1109/MCSE.2022.3163817},
   issn = {1558-366X},
   issue = {2},
   journal = {Computing in Science & Engineering},
   keywords = {Central processing units,Companies,Graphics processing units,Product design,Product development},
   month = {3},
   note = {Conference Name: Computing in Science & Engineering},
   pages = {95-100},
   title = {Nvidia Hopper GPU and Grace CPU Highlights},
   volume = {24},
   year = {2022},
}
@article{Choquette2021,
   abstract = {NVIDIA A100 Tensor Core GPU is NVIDIA's latest flagship GPU. It has been designed with many new innovative features to provide performance and capabilities for HPC, AI, and data analytics workloads. Feature enhancements include a Third-Generation Tensor Core, new asynchronous data movement and programming model, enhanced L2 cache, HBM2 DRAM, and third-generation NVIDIA NVLink I/O. © 1981-2012 IEEE.},
   author = {J Choquette and W Gandhi and O Giroux and N Stam and R Krashinsky},
   doi = {10.1109/MM.2021.3061394},
   issn = {0272-1732},
   issue = {2},
   journal = {IEEE Micro},
   keywords = {A100,C++20,CUDA,Deep Learning,GPU,NVLink,Tensor Core},
   note = {Cited By :62},
   pages = {29-35},
   title = {NVIDIA A100 Tensor Core GPU: Performance and Innovation},
   volume = {41},
   year = {2021},
}
@article{Siebesma2003,
   author = {A Pier Siebesma and Christopher S Bretherton and Andrew Brown and Andreas Chlond and Joan Cuxart and Peter G Duynkerke and Hongli Jiang and Marat Khairoutdinov and David Lewellen and Chin-Hoh Moeng and Enrique Sanchez and Bjorn Stevens and David E Stevens},
   doi = {10.1175/1520-0469(2003)60<1201:ALESIS>2.0.CO;2},
   issue = {10},
   journal = {Journal of the Atmospheric Sciences},
   month = {5},
   note = {Place: Boston MA, USA
Publisher: American Meteorological Society},
   pages = {1201-1219},
   title = {A Large Eddy Simulation Intercomparison Study of Shallow Cumulus Convection},
   volume = {60},
   url = {https://journals.ametsoc.org/view/journals/atsc/60/10/1520-0469_2003_60_1201_alesis_2.0.co_2.xml},
   year = {2003},
}
@generic{,
   title = {Refactoring and Optimizing WRF Model on Sunway TaihuLight  Proceedings of the 48th International Conference on Parallel Processing},
   url = {https://dl.acm.org/doi/10.1145/3337821.3337923},
}
